{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Vox celeb Dataset in the notebook directly from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"101arrowz/vox_celeb\",'audio',trust_remote_code=True)\n",
    "for sample in dataset:\n",
    "    print(sample)\n",
    "    break  # Process sample-by-sample without full download\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from torchaudio.datasets import VoxCeleb1\n",
    "\n",
    "dataset = VoxCeleb1(root=, download=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def read_voxceleb_trials(trial_file):\n",
    "    \"\"\"Reads the VoxCeleb1 trial file.\"\"\"\n",
    "    pairs = []\n",
    "    with open(trial_file, 'r') as f:\n",
    "        for line in f:\n",
    "            label, path1, path2 = line.strip().split()\n",
    "            pairs.append((path1, path2, int(label)))\n",
    "    return pairs\n",
    "\n",
    "trial_file = \"/path/to/voxceleb1_trials.txt\"\n",
    "trials = read_voxceleb_trials(trial_file)\n",
    "print(f\"Loaded {len(trials)} test pairs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Example: Scores from cosine similarity (replace with actual values)\n",
    "genuine_scores = np.array([0.85, 0.92, 0.88, 0.91])  # Same speaker\n",
    "impostor_scores = np.array([0.30, 0.45, 0.28, 0.40])  # Different speakers\n",
    "\n",
    "# Assign labels\n",
    "genuine_labels = np.ones_like(genuine_scores)  # 1 for same speaker\n",
    "impostor_labels = np.zeros_like(impostor_scores)  # 0 for different speaker\n",
    "\n",
    "# Combine scores and labels\n",
    "scores = np.concatenate([genuine_scores, impostor_scores])\n",
    "labels = np.concatenate([genuine_labels, impostor_labels])\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(labels, scores, pos_label=1)\n",
    "\n",
    "# Compute EER where FAR ≈ FRR\n",
    "fnr = 1 - tpr  # False Negative Rate\n",
    "eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n",
    "\n",
    "print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "print(f\"EER Threshold: {eer_threshold:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "voxceleb_path = \"./wav\"  # Change this to your actual dataset path\n",
    "print(f\"Dataset path: {voxceleb_path}\")\n",
    "print(f\"Path exists: {os.path.exists(voxceleb_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Step 1: Load the Titanet Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EncDecSpeakerLabelModel.from_pretrained(\"titanet_large\").to(device)\n",
    "\n",
    "# Step 2: Load VoxCeleb Dataset\n",
    "voxceleb_path = \"./wav\"  # Change this to your actual dataset path\n",
    "wav_files = glob.glob(os.path.join(voxceleb_path, \"**\", \"*.wav\"), recursive=True)\n",
    "\n",
    "# Step 3: Function to Extract Speaker Embeddings\n",
    "def extract_embedding(file_path):\n",
    "    emb = model.get_embedding(file_path).detach().cpu().numpy()\n",
    "    return emb.squeeze()\n",
    "\n",
    "\n",
    "# Step 4: Generate Speaker Verification Pairs\n",
    "num_samples = min(1000, len(wav_files))  # Use a subset if dataset is large\n",
    "cos_sim = []\n",
    "labels = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    emb1 = extract_embedding(wav_files[i])\n",
    "    \n",
    "    \n",
    "    # Choose a second file randomly\n",
    "    j = np.random.randint(0, len(wav_files))\n",
    "    emb2 = extract_embedding(wav_files[j])\n",
    "    \n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    \n",
    "    # Label: 1 if same speaker, 0 otherwise (Assumption: Folder structure contains speaker IDs)\n",
    "    label = 1 if os.path.dirname(wav_files[i]) == os.path.dirname(wav_files[j]) else 0\n",
    "    \n",
    "    cos_sim.append(similarity)\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "# Step 5: Compute EER\n",
    "fpr, tpr, thresholds = roc_curve(labels,cos_sim,pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n",
    "print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Step 1: Load the Titanet Model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EncDecSpeakerLabelModel.from_pretrained(\"ecapa_tdnn\").to(device)\n",
    "\n",
    "# Step 2: Load VoxCeleb Dataset\n",
    "voxceleb_path = \"./wav\"  # Change this to your actual dataset path\n",
    "wav_files = glob.glob(os.path.join(voxceleb_path, \"**\", \"*.wav\"), recursive=True)\n",
    "\n",
    "# Step 3: Function to Extract Speaker Embeddings\n",
    "def extract_embedding(file_path):\n",
    "    emb = model.get_embedding(file_path).detach().cpu().numpy()\n",
    "    return emb.squeeze()\n",
    "\n",
    "\n",
    "# Step 4: Generate Speaker Verification Pairs\n",
    "num_samples = min(1000, len(wav_files))  # Use a subset if dataset is large\n",
    "cos_sim = []\n",
    "labels = []\n",
    "\n",
    "for i in range(num_samples):\n",
    "    emb1 = extract_embedding(wav_files[i])\n",
    "    \n",
    "    \n",
    "    # Choose a second file randomly\n",
    "    j = np.random.randint(0, len(wav_files))\n",
    "    emb2 = extract_embedding(wav_files[j])\n",
    "    \n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "    \n",
    "    # Label: 1 if same speaker, 0 otherwise (Assumption: Folder structure contains speaker IDs)\n",
    "    label = 1 if os.path.dirname(wav_files[i]) == os.path.dirname(wav_files[j]) else 0\n",
    "    \n",
    "    cos_sim.append(similarity)\n",
    "    labels.append(label)\n",
    "\n",
    "\n",
    "# Step 5: Compute EER\n",
    "fpr, tpr, thresholds = roc_curve(labels,cos_sim,pos_label=1)\n",
    "fnr = 1 - tpr\n",
    "eer_threshold = thresholds[np.nanargmin(np.abs(fpr - fnr))]\n",
    "eer = fpr[np.nanargmin(np.abs(fpr - fnr))]\n",
    "print(f\"Equal Error Rate (EER): {eer:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import itertools\n",
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EncDecSpeakerLabelModel.from_pretrained(\"ecapa_tdnn\").to(device)\n",
    "model.eval()\n",
    "\n",
    "voxceleb_path = \"./wav\"  # Set your dataset path\n",
    "wav_files = glob.glob(os.path.join(voxceleb_path, \"**\", \"*.wav\"), recursive=True)\n",
    "\n",
    "# Dictionary to store speaker-wise files\n",
    "speaker_dict = {}\n",
    "\n",
    "for file in wav_files:\n",
    "    parts = file.split(os.sep)  # Splitting path using OS-specific separator\n",
    "    speaker_id = parts[-3]  # Extracting speaker ID (Assumes structure: speaker_id/video_id/audio.wav)\n",
    "\n",
    "    if speaker_id not in speaker_dict:\n",
    "        speaker_dict[speaker_id] = []\n",
    "    \n",
    "    speaker_dict[speaker_id].append(file)\n",
    "\n",
    "# Placeholder function for extracting embeddings (Replace with real model)\n",
    "def extract_embedding(file_path):\n",
    "    emb = model.get_embedding(file_path).detach().cpu().numpy()\n",
    "    # print(\"Embedding shape before squeeze:\", emb.shape)\n",
    "    # emb = emb.squeeze()\n",
    "    # print(\"Embedding shape after squeeze:\", emb.shape)\n",
    "    return emb.squeeze()\n",
    "\n",
    "\n",
    "# List to store cosine similarity results\n",
    "cosine_results = []\n",
    "\n",
    "# 1️⃣ **Compute cosine similarity for intra-speaker pairs (label 1)**\n",
    "for speaker, files in speaker_dict.items():\n",
    "    for f1, f2 in itertools.combinations(files, 2):\n",
    "        emb1 = extract_embedding(f1)\n",
    "        emb2 = extract_embedding(f2)\n",
    "        similarity = 1 - cosine(emb1, emb2)  # Cosine similarity calculation\n",
    "        cosine_results.append((1, f1, f2, similarity))\n",
    "\n",
    "# 2️⃣ **Compute cosine similarity for inter-speaker pairs (label 0)**\n",
    "speakers = list(speaker_dict.keys())\n",
    "\n",
    "for i in range(len(speakers)):\n",
    "    for j in range(i + 1, len(speakers)):  # Ensure unique speaker pairs\n",
    "        spk1_files = speaker_dict[speakers[i]]\n",
    "        spk2_files = speaker_dict[speakers[j]]\n",
    "        \n",
    "        for f1, f2 in itertools.product(spk1_files, spk2_files):\n",
    "            emb1 = extract_embedding(f1)\n",
    "            emb2 = extract_embedding(f2)\n",
    "            similarity = 1 - cosine(emb1, emb2)  # Cosine similarity calculation\n",
    "            cosine_results.append((0, f1, f2, similarity))\n",
    "\n",
    "# Print a sample of the cosine similarity results to verify format\n",
    "for result in cosine_results[:10]:\n",
    "    print(result[0], result[1], result[2], result[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_titanet():\n",
    "    \"\"\"Load the Titanet speaker embedding model.\"\"\"\n",
    "    model = EncDecSpeakerLabelModel.from_pretrained(model_name=\"titanet_large\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def extract_embedding(model, audio_path):\n",
    "    \"\"\"Extract speaker embedding from an audio file using the correct API.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        embedding = model.get_embedding(audio_path).cpu().numpy().flatten()\n",
    "    return embedding\n",
    "\n",
    "def process_voxceleb(voxceleb_dir, model, output_pickle, output_txt):\n",
    "    \"\"\"Process all audio files in the VoxCeleb directory and store embeddings.\"\"\"\n",
    "    embeddings = {}\n",
    "    \n",
    "    with open(output_txt, \"w\") as txt_file:\n",
    "        for root, _, files in os.walk(voxceleb_dir):\n",
    "            for file in tqdm(files):\n",
    "                if file.endswith(\".wav\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    speaker_id = os.path.basename(root)  # Assuming structure: VoxCeleb/speaker_id/audio.wav\n",
    "                    key = f\"{speaker_id}@{file}\"\n",
    "                    embedding = extract_embedding(model, file_path)\n",
    "                    embeddings[key] = embedding\n",
    "                    \n",
    "                    # Save in text format\n",
    "                    txt_file.write(f\"{key}: {embedding.tolist()}\\n\")\n",
    "    \n",
    "    with open(output_pickle, \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "    print(f\"Embeddings saved to {output_pickle} and {output_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    voxceleb_dir = \"./wav\"  # Change this to your local VoxCeleb directory\n",
    "    output_pickle = \"speaker_embeddings.pkl\"\n",
    "    output_txt = \"speaker_embeddings.txt\"\n",
    "    \n",
    "    model = load_titanet()\n",
    "    process_voxceleb(voxceleb_dir, model, output_pickle, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "from nemo.collections.asr.models import EncDecSpeakerLabelModel\n",
    "from omegaconf import OmegaConf\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_titanet():\n",
    "    \"\"\"Load the Titanet speaker embedding model.\"\"\"\n",
    "    model = EncDecSpeakerLabelModel.restore_from(\"titanet-mera.nemo\")\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def extract_embedding(model, audio_path):\n",
    "    \"\"\"Extract speaker embedding from an audio file using the correct API.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        embedding = model.get_embedding(audio_path).cpu().numpy().flatten()\n",
    "    return embedding\n",
    "\n",
    "def process_voxceleb(voxceleb_dir, model, output_pickle, output_txt):\n",
    "    \"\"\"Process all audio files in the VoxCeleb directory and store embeddings.\"\"\"\n",
    "    embeddings = {}\n",
    "    \n",
    "    with open(output_txt, \"w\") as txt_file:\n",
    "        for root, dirs, files in os.walk(voxceleb_dir):\n",
    "            if files:  # Only process if there are audio files\n",
    "                speaker_id = os.path.basename(os.path.dirname(root))  # Get the speaker ID from the parent directory\n",
    "                for file in tqdm(files):\n",
    "                    if file.endswith(\".wav\"):\n",
    "                        file_path = os.path.join(root, file)\n",
    "                        key = f\"{speaker_id}@{file}\"\n",
    "                        embedding = extract_embedding(model, file_path)\n",
    "                        embeddings[key] = embedding\n",
    "                        \n",
    "                        # Save in text format\n",
    "                        txt_file.write(f\"{key}: {embedding.tolist()}\\n\")\n",
    "    \n",
    "    with open(output_pickle, \"wb\") as f:\n",
    "        pickle.dump(embeddings, f)\n",
    "    print(f\"Embeddings saved to {output_pickle} and {output_txt}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    voxceleb_dir = \"./wav\"  # Change this to your local VoxCeleb directory\n",
    "    output_pickle = \"speaker_embeddings-mera-vox.pkl\"\n",
    "    output_txt = \"speaker_embeddings-mera-vox.txt\"\n",
    "    \n",
    "    model = load_titanet()\n",
    "    process_voxceleb(voxceleb_dir, model, output_pickle, output_txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def verify_files(text_file, root_directory):\n",
    "    with open(text_file, 'r') as f:\n",
    "        missing_files = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            match = re.match(r\"(\\w+)@([\\w.]+)\", line)\n",
    "            if match:\n",
    "                folder, filename = match.groups()\n",
    "                folder_path = os.path.join(root_directory, folder)\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                if not os.path.exists(file_path):\n",
    "                    missing_files.append(file_path)\n",
    "    \n",
    "    if missing_files:\n",
    "        print(\"The following files are missing:\")\n",
    "        for file in missing_files:\n",
    "            print(file)\n",
    "    else:\n",
    "        print(\"All files are present.\")\n",
    "\n",
    "# Example usage\n",
    "text_file = \"./speaker_embeddings.txt\"  # Text file containing the filenames\n",
    "root_directory = \"./wav\"  # Update this to your actual root folder\n",
    "verify_files(text_file, root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import pickle as pkl\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import brentq\n",
    "from sklearn.metrics import roc_curve\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "This script faciliates to get EER % based on cosine-smilarity \n",
    "for Voxceleb dataset.\n",
    "\n",
    "Args:\n",
    "    trial_file str: path to voxceleb trial file\n",
    "    emb : path to pickle file of embeddings dictionary (generated from spkr_get_emb.py)\n",
    "    save_kaldi_emb: if required pass this argument to save kaldi embeddings for KALDI PLDA training later\n",
    "    Note: order of audio files in manifest file should match the embeddings\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def get_acc(trial_file='', emb='', save_kaldi_emb=False):\n",
    "\n",
    "    trial_score = open('trial_score.txt', 'w')\n",
    "    dirname = os.path.dirname(trial_file)\n",
    "    with open(emb, 'rb') as f:\n",
    "        emb = pkl.load(f)\n",
    "    trial_embs = []\n",
    "    keys = []\n",
    "    all_scores = []\n",
    "    all_keys = []\n",
    "\n",
    "    # for each trials in trial file\n",
    "    with open(trial_file, 'r') as f:\n",
    "        tmp_file = f.readlines()\n",
    "        for line in tqdm(tmp_file):\n",
    "            line = line.strip()\n",
    "            truth, x_speaker, y_speaker = line.split()\n",
    "\n",
    "            x_speaker = x_speaker.split('/')\n",
    "            x_speaker = '@'.join(x_speaker)\n",
    "\n",
    "            y_speaker = y_speaker.split('/')\n",
    "            y_speaker = '@'.join(y_speaker)\n",
    "\n",
    "            X = emb[x_speaker]\n",
    "            Y = emb[y_speaker]\n",
    "\n",
    "            if save_kaldi_emb and x_speaker not in keys:\n",
    "                keys.append(x_speaker)\n",
    "                trial_embs.extend([X])\n",
    "\n",
    "            if save_kaldi_emb and y_speaker not in keys:\n",
    "                keys.append(y_speaker)\n",
    "                trial_embs.extend([Y])\n",
    "\n",
    "            score = np.dot(X, Y) / ((np.dot(X, X) * np.dot(Y, Y)) ** 0.5)\n",
    "            score = (score + 1) / 2\n",
    "\n",
    "            all_scores.append(score)\n",
    "            trial_score.write(str(score) + \"\\t\" + truth)\n",
    "            truth = int(truth)\n",
    "            all_keys.append(truth)\n",
    "\n",
    "            trial_score.write('\\n')\n",
    "    trial_score.close()\n",
    "\n",
    "    if save_kaldi_emb:\n",
    "        np.save(dirname + '/all_embs_voxceleb.npy', np.asarray(trial_embs))\n",
    "        np.save(dirname + '/all_ids_voxceleb.npy', np.asarray(keys))\n",
    "        print(\"Saved KALDI PLDA related embeddings to {}\".format(dirname))\n",
    "\n",
    "    return np.asarray(all_scores), np.asarray(all_keys)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--trial_file\", help=\"path to voxceleb trial file\", type=str, required=True)\n",
    "    parser.add_argument(\"--emb\", help=\"path to numpy file of embeddings\", type=str, required=True)\n",
    "    parser.add_argument(\n",
    "        \"--save_kaldi_emb\",\n",
    "        help=\":save kaldi embeddings for KALDI PLDA training later\",\n",
    "        required=False,\n",
    "        action='store_true',\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    trial_file, emb, save_kaldi_emb = args.trial_file, args.emb, args.save_kaldi_emb\n",
    "\n",
    "    y_score, y = get_acc(trial_file=trial_file, emb=emb, save_kaldi_emb=save_kaldi_emb)\n",
    "    fpr, tpr, thresholds = roc_curve(y, y_score, pos_label=1)\n",
    "\n",
    "    eer = brentq(lambda x: 1.0 - x - interp1d(fpr, tpr)(x), 0.0, 1.0)\n",
    "    sys.stdout.write(\"{0:.2f}\\n\".format(eer * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_middle_folder(input_file, output_file):\n",
    "    with open(input_file, 'r') as infile, open(output_file, 'w') as outfile:\n",
    "        for line in infile:\n",
    "            parts = line.strip().split()\n",
    "            processed_parts = [parts[0]] + [re.sub(r'/[^/]+/', '/', path) for path in parts[1:]]\n",
    "            outfile.write(\" \".join(processed_parts) + \"\\n\")\n",
    "\n",
    "# Example usage:\n",
    "input_file = \"./vox-test.txt\"  # Replace with your input filename\n",
    "output_file = \"./vox_test2.txt\"  # Replace with your output filename\n",
    "remove_middle_folder(input_file, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Speaker_Verification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
